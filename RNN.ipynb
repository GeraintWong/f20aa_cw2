{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66abcd2-4dd8-417b-9df1-d49293e55b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b63682-6cf6-4e04-bdb2-cf662eb35b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I received this product early from the seller!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>*****&lt;br /&gt;Numi's Collection Assortment Melang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I was very careful not to overcook this pasta,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Buying this multi-pack I was misled by the pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>These bars are so good! I loved them warmed up...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      5  I received this product early from the seller!...\n",
       "1      5  *****<br />Numi's Collection Assortment Melang...\n",
       "2      5  I was very careful not to overcook this pasta,...\n",
       "3      5  Buying this multi-pack I was misled by the pic...\n",
       "4      5  These bars are so good! I loved them warmed up..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447f2e62-e388-4ed7-96e2-faf31b9f7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702d5dd5-2772-4309-bb9b-bbeab9e6827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000  # Number of unique words to keep\n",
    "SEQUENCE_LENGTH = 100  # Fixed length of input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b479572c-106a-4e38-8999-99a28191e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['Text'].values\n",
    "Y_train = train_df['Score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1a52c8-9613-41b5-b6bc-0244f8d91187",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQUENCE_LENGTH  # Ensures uniform length\n",
    ")\n",
    "\n",
    "# Fit the TextVectorization layer to the text data\n",
    "encoder.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04c9c42-f0f1-47eb-b097-987d17bd1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '[UNK]' 'the' 'i' 'and' 'a' 'to' 'it' 'of' 'is' 'this' 'in' 'for' 'my'\n",
      " 'that' 'but' 'with' 'have' 'you' 'not']\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "print(vocab[:20])  # Display the first 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d6cc971-5b7b-4bee-9b03-c1f6ce77f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10    9    5 1073  378    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Sample text to test the encoder\n",
    "sample_text = \"This is a sample review.\"\n",
    "\n",
    "# Use the encoder to transform the text into integers\n",
    "encoded_text = encoder(tf.constant([sample_text]))\n",
    "\n",
    "# Display the result\n",
    "print(encoded_text.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b322639-9dc7-4150-9c5b-55c6d14c6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = encoder(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6687459-dbb9-482e-9160-a4a9adb4ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure X_train_vectorized is a NumPy array\n",
    "X_train_vectorized_np = X_train_vectorized.numpy() if isinstance(X_train_vectorized, tf.Tensor) else X_train_vectorized\n",
    "\n",
    "# Split data into training and validation sets (80% training, 20% validation)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_vectorized_np, Y_train, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cb4da85-734d-4f82-8842-b898d4e16195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (247304, 100)\n",
      "Shape of X_val: (61827, 100)\n",
      "Sample of tokenized X_train (first 3 samples):\n",
      "[[   3   35  155    6  218   14    2  138 1679 5944  378    9   19   81\n",
      "    18  265  136  214    8   33    2   78    8 2140   10  852 1644 6691\n",
      "     4   14   73  117   46 2589   36   18  440   73  378  109 1261  128\n",
      "   194  552   33   28  356  364    9  538   12    2 3904    2 6370 6565\n",
      "    11    2  393    4 1767 1535  175   14   36  374 1185   21 2657  214\n",
      "    32    2    1   24    2  532   59   71 7527  112  839    7  322   19\n",
      "   763   26   46   37   96 2542   73  117   15  285   77  964   19  189\n",
      "     7 1750]\n",
      " [  51  120    2  386 1354   26   14   51  130   99 1634  172   51   55\n",
      "    29   42   23   21  188    6   72   87   40  296  718   51  211   53\n",
      "    31  215   48    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   3   17 1611  433    4  419    2  582 3613   39   84    3   17  120\n",
      "     4   27    5  170    3   68   27    6 1581   13  433 1115    4    3\n",
      "   582    7  307    5  482   26    7  535 1611   24    2 3212    4 1460\n",
      "    27 3721   24    2  695    3  404   10 1336    7   64  115   13  433\n",
      "   432   15   19    1    7  653   64   30   71   42   28  198   83    3\n",
      "   166  887   14   10  804   41 1242   13 1340   77    3   17   85  189\n",
      "    42    2  198    4  506    2    1   50  658  233    3   46  136   33\n",
      "   380  272]]\n",
      "Sample of tokenized X_val (first 3 samples):\n",
      "[[  40    1    6  131   90   40  765  153   73 5444  662   53   82   48\n",
      "   204   80    1  271  274  445    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2058   32  747   12  469   32  657   36   18   27    6 2322   18  265\n",
      "    17   10  747    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   3  103    7   72    7   11   13  433    4   72   22    5 4065   13\n",
      "   730  340 2710    4    1  438  178 2157    3   17  691  294  730    4\n",
      "    10  151   19  794   54   58   13 9269   50   64 1611  730    4    7\n",
      "   417   40   24  310   22   96   10  288  203    9  460    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_train and X_val\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")\n",
    "\n",
    "# Print the first few tokenized sequences from X_train\n",
    "print(f\"Sample of tokenized X_train (first 3 samples):\\n{X_train[:3]}\")\n",
    "\n",
    "# Print the first few tokenized sequences from X_val\n",
    "print(f\"Sample of tokenized X_val (first 3 samples):\\n{X_val[:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060cb37b-5a5f-4bc8-af6f-bf7ae7b728ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in X_train:\n",
      "False\n",
      "Checking for missing values in X_val:\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in X_train:\")\n",
    "print(np.any(np.isnan(X_train)))\n",
    "\n",
    "print(\"Checking for missing values in X_val:\")\n",
    "print(np.any(np.isnan(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29802179-2f65-429d-a534-5c4548e3c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length in X_train: 100\n",
      "Maximum length in X_train: 100\n",
      "Average length in X_train: 100.0\n",
      "Minimum length in X_val: 100\n",
      "Maximum length in X_val: 100\n",
      "Average length in X_val: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Check the length of tokenized sequences\n",
    "train_lengths = [len(seq) for seq in X_train]\n",
    "val_lengths = [len(seq) for seq in X_val]\n",
    "\n",
    "print(f\"Minimum length in X_train: {np.min(train_lengths)}\")\n",
    "print(f\"Maximum length in X_train: {np.max(train_lengths)}\")\n",
    "print(f\"Average length in X_train: {np.mean(train_lengths)}\")\n",
    "\n",
    "print(f\"Minimum length in X_val: {np.min(val_lengths)}\")\n",
    "print(f\"Maximum length in X_val: {np.max(val_lengths)}\")\n",
    "print(f\"Average length in X_val: {np.mean(val_lengths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7691dfc-61d1-4cd1-b893-365331e13e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any tokens in X_train exceed VOCAB_SIZE? False\n",
      "Any tokens in X_val exceed VOCAB_SIZE? False\n"
     ]
    }
   ],
   "source": [
    "# Check if any token exceeds VOCAB_SIZE\n",
    "exceeds_vocab_train = np.any(X_train >= VOCAB_SIZE)\n",
    "exceeds_vocab_val = np.any(X_val >= VOCAB_SIZE)\n",
    "\n",
    "print(f\"Any tokens in X_train exceed VOCAB_SIZE? {exceeds_vocab_train}\")\n",
    "print(f\"Any tokens in X_val exceed VOCAB_SIZE? {exceeds_vocab_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143cecb5-8aec-471b-9eb2-9cf4f8ffff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sample (before): ['This is a sample sentence.', 'Another example sentence here.']\n",
      "Tokenized Sample (after): [[  10    9    5 1073    1    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [ 242 1967    1  204    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "sample_text = [\"This is a sample sentence.\", \"Another example sentence here.\"]\n",
    "tokenized_sample = encoder(sample_text)\n",
    "\n",
    "print(f\"Tokenized Sample (before): {sample_text}\")\n",
    "print(f\"Tokenized Sample (after): {tokenized_sample.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "436ba1da-48ff-47b0-a208-aef07ca0560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m640,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">714,629</span> (2.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m714,629\u001b[0m (2.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">714,629</span> (2.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m714,629\u001b[0m (2.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(100,), dtype=tf.int32),  # Explicit input shape\n",
    "    tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=64, mask_zero=True),  \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),  \n",
    "    tf.keras.layers.Dense(64, activation='relu'),  \n",
    "    tf.keras.layers.Dense(5, activation='softmax')  \n",
    "])\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a3c3b7-b8fd-4c7d-834f-eaa087b7dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d8b4251-fe13-4793-88f2-760353387beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 45ms/step - accuracy: 0.6901 - loss: 0.8498 - val_accuracy: 0.7313 - val_loss: 0.7133\n",
      "Epoch 2/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 45ms/step - accuracy: 0.7427 - loss: 0.6735 - val_accuracy: 0.7409 - val_loss: 0.6899\n",
      "Epoch 3/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 53ms/step - accuracy: 0.7661 - loss: 0.6081 - val_accuracy: 0.7398 - val_loss: 0.6948\n",
      "Epoch 4/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1564s\u001b[0m 202ms/step - accuracy: 0.7877 - loss: 0.5535 - val_accuracy: 0.7390 - val_loss: 0.7131\n",
      "Epoch 5/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 80ms/step - accuracy: 0.8106 - loss: 0.4955 - val_accuracy: 0.7358 - val_loss: 0.7569\n",
      "Epoch 6/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 83ms/step - accuracy: 0.8341 - loss: 0.4370 - val_accuracy: 0.7225 - val_loss: 0.8183\n",
      "Epoch 7/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 73ms/step - accuracy: 0.8527 - loss: 0.3853 - val_accuracy: 0.7072 - val_loss: 0.9198\n",
      "Epoch 8/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1778s\u001b[0m 230ms/step - accuracy: 0.8754 - loss: 0.3325 - val_accuracy: 0.7175 - val_loss: 1.0347\n",
      "Epoch 9/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 78ms/step - accuracy: 0.8938 - loss: 0.2862 - val_accuracy: 0.7079 - val_loss: 1.1592\n",
      "Epoch 10/10\n",
      "\u001b[1m7729/7729\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 60ms/step - accuracy: 0.9092 - loss: 0.2474 - val_accuracy: 0.6986 - val_loss: 1.3005\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "Y_train_fixed = np.array(Y_train) - 1  # Shift labels from [1-5] to [0-4]\n",
    "Y_val_fixed = np.array(Y_val) - 1  # Shift validation labels similarly\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "Y_train_one_hot = to_categorical(Y_train_fixed, num_classes=5)\n",
    "Y_val_one_hot = to_categorical(Y_val_fixed, num_classes=5)\n",
    "\n",
    "\n",
    "# Now fit the model with one-hot encoded labels\n",
    "history = model.fit(\n",
    "    X_train, Y_train_one_hot,  # Use one-hot encoded labels\n",
    "    validation_data=(X_val, Y_val_one_hot),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c9151c7-38f7-4284-b870-f1cf50545d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c1a9d27-c982-4ddc-81c6-3309fc737a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fog chaser was the best both in flavor and bod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We found this at PF Changs, and it tastes just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not quite a chocolate bar substitute but delic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is not as tasty as Pamela's Almond Biscot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;a href=\"http://www.amazon.com/gp/product/B000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Text\n",
       "0   0  Fog chaser was the best both in flavor and bod...\n",
       "1   1  We found this at PF Changs, and it tastes just...\n",
       "2   2  Not quite a chocolate bar substitute but delic...\n",
       "3   3  This is not as tasty as Pamela's Almond Biscot...\n",
       "4   4  <a href=\"http://www.amazon.com/gp/product/B000..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3623a28-3dec-4943-bbdd-ab1c3eb84ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract the text column\n",
    "X_test = test[\"Text\"].values  # Assuming 'Text' is the column name\n",
    "\n",
    "# Apply the same TextVectorization layer\n",
    "X_test_vectorized = encoder(X_test)  # Uses the same encoder from training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c07fd7d2-d84b-4b46-a567-d020245383c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(119662, 100), dtype=int64, numpy=\n",
       "array([[4214, 4962,   20, ...,    0,    0,    0],\n",
       "       [  51,  111,   10, ...,    0,    0,    0],\n",
       "       [  19,  250,    5, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   3,   55,  264, ...,    0,    0,    0],\n",
       "       [  51,  103,    5, ...,    2,  279,  129],\n",
       "       [   3,   82,   10, ...,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f57ed8e-4d0f-4a44-a2b2-74bd5ef5292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3740/3740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities\n",
    "predictions = model.predict(X_test_vectorized)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = predictions.argmax(axis=1)  # Get class index with highest probability\n",
    "\n",
    "# If labels start from 1 (not 0), adjust\n",
    "y_pred += 1  # Convert 0-based indices to 1-based labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a3f23e7-fee6-44c2-8ed6-83a05f65ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv ✅\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "\n",
    "# Replace the label column with predictions\n",
    "sample_submission[\"Score\"] = y_pred  # Ensure the column name matches Kaggle's expected output\n",
    "\n",
    "# Save as submission.csv\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved as submission.csv ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5300250d-33cf-4d48-81a5-25d6b8d9a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_submitted=pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a499685-1447-4a53-9ef3-f048fdb824c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119662.000000</td>\n",
       "      <td>119662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59830.500000</td>\n",
       "      <td>4.192425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34543.588293</td>\n",
       "      <td>1.342349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29915.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>59830.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89745.750000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>119661.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id          Score\n",
       "count  119662.000000  119662.000000\n",
       "mean    59830.500000       4.192425\n",
       "std     34543.588293       1.342349\n",
       "min         0.000000       1.000000\n",
       "25%     29915.250000       4.000000\n",
       "50%     59830.500000       5.000000\n",
       "75%     89745.750000       5.000000\n",
       "max    119661.000000       5.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_submitted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1fd0472-1aac-4413-bee0-eacb811a9f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Score\n",
       "0   0      5\n",
       "1   1      5\n",
       "2   2      5\n",
       "3   3      3\n",
       "4   4      5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_submitted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b34677-06e6-4868-a751-9cd53fd4887f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
