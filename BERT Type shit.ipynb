{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":11278121,"datasetId":7050928,"databundleVersionId":11696103},{"sourceType":"datasetVersion","sourceId":11294782,"datasetId":7062458,"databundleVersionId":11714830},{"sourceType":"datasetVersion","sourceId":11266192,"datasetId":7042223,"databundleVersionId":11682498}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install stopwords\n!pip install flair\n!pip install nltk\n!pip install swifter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:08:41.521541Z","iopub.execute_input":"2025-04-06T06:08:41.521748Z","iopub.status.idle":"2025-04-06T06:09:10.771806Z","shell.execute_reply.started":"2025-04-06T06:08:41.521727Z","shell.execute_reply":"2025-04-06T06:09:10.770870Z"}},"outputs":[{"name":"stdout","text":"Collecting stopwords\n  Downloading stopwords-1.0.1-py2.py3-none-any.whl.metadata (1.9 kB)\nDownloading stopwords-1.0.1-py2.py3-none-any.whl (37 kB)\nInstalling collected packages: stopwords\nSuccessfully installed stopwords-1.0.1\nCollecting flair\n  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair) (1.36.23)\nCollecting conllu<5.0.0,>=4.0 (from flair)\n  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.15)\nCollecting ftfy>=6.1.0 (from flair)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.2.0)\nRequirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.29.0)\nCollecting langdetect>=1.0.9 (from flair)\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (5.3.0)\nRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.5)\nRequirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.5.0)\nRequirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.10)\nCollecting pptree>=3.1 (from flair)\n  Downloading pptree-3.1.tar.gz (3.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.9.0.post0)\nCollecting pytorch-revgrad>=0.2.0 (from flair)\n  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2024.11.6)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\nCollecting segtok>=1.5.11 (from flair)\n  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\nCollecting sqlitedict>=2.0.0 (from flair)\n  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\nRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.5.1+cu121)\nRequirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.67.1)\nCollecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.47.0)\nCollecting wikipedia-api>=0.5.7 (from flair)\n  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting bioc<3.0.0,>=2.0.0 (from flair)\n  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\nCollecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: botocore<1.37.0,>=1.36.23 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.36.23)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (0.11.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.17.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.17.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.7)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.2.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->flair) (3.4.2)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->flair) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.4.5)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.20.3)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.37.0,>=1.36.23->boto3>=1.20.27->flair) (2.3.0)\nRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2.4.1)\nRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.2.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\nRequirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib>=2.2.3->flair) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.20->matplotlib>=2.2.3->flair) (2024.2.0)\nDownloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\nDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\nDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\nDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nBuilding wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=98f8d1a30c398880038905de62b65ffd508cbce4560b4924f5e45864990011c4\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=58f6fab17878b1859675ad9c2f49d22e6770db7ce63f7203ae78b43f90c67cf4\n  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=747857af57efc49e91fdb8355f252df442348202071c3037bd0a8a11054381b5\n  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=d60683a724068739ade1823537752459e0782b10b491104df4af04f2e84b1397\n  Stored in directory: /root/.cache/pip/wheels/1d/f8/07/0508c38722dcd82ee355e9d85e33c9e9471d4bec0f8ae72de0\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=2a54a6b024187e093b1f01185c57d2d8211c0f12c1bc2c6b8ec5c40d38383d7a\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=4b216caaa35dcbd9e3cbc92dda75131899f90e0efd0f4026a6d1b5f64d9a7666\n  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\nSuccessfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\nInstalling collected packages: sqlitedict, pptree, docopt, segtok, langdetect, jsonlines, intervaltree, ftfy, conllu, wikipedia-api, bioc, transformer-smaller-training-vocab, pytorch-revgrad, flair\nSuccessfully installed bioc-2.1 conllu-4.5.3 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jsonlines-4.0.0 langdetect-1.0.9 pptree-3.1 pytorch-revgrad-0.2.0 segtok-1.5.11 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.0 wikipedia-api-0.8.1\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nCollecting swifter\n  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (2.2.3)\nRequirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.10/dist-packages (from swifter) (5.9.5)\nRequirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2024.12.1)\nRequirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (4.67.1)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.7)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.0)\nRequirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2024.12.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.2)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.2)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.1)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.5.0)\nRequirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.21)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2025.1)\nRequirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]>=2.10.0->swifter) (19.0.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.21.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas>=1.0.0->swifter) (2.4.1)\nRequirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas>=1.0.0->swifter) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas>=1.0.0->swifter) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas>=1.0.0->swifter) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas>=1.0.0->swifter) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas>=1.0.0->swifter) (2024.2.0)\nBuilding wheels for collected packages: swifter\n  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16507 sha256=65d766bb35060e95fac539f07b6fa270ace78db8d91270f92fabaa12838272ee\n  Stored in directory: /root/.cache/pip/wheels/e4/cf/51/0904952972ee2c7aa3709437065278dc534ec1b8d2ad41b443\nSuccessfully built swifter\nInstalling collected packages: swifter\nSuccessfully installed swifter-1.4.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install dependencies as needed:\n# pip install kagglehub[pandas-datasets]\nimport kagglehub\nfrom kagglehub import KaggleDatasetAdapter\n\n# Set the path to the file you'd like to load\nfile_path = \"train_processed.csv\"\n\n# Load the latest version\ntrain_df = kagglehub.load_dataset(\n  KaggleDatasetAdapter.PANDAS,\n  \"buddycyph/train-processed\",\n  file_path,\n  # Provide any additional arguments like \n  # sql_query or pandas_kwargs. See the \n  # documenation for more information:\n  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n)\n\nprint(\"First 5 records:\", train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:48:58.624110Z","iopub.execute_input":"2025-04-06T06:48:58.624505Z","iopub.status.idle":"2025-04-06T06:49:01.123048Z","shell.execute_reply.started":"2025-04-06T06:48:58.624476Z","shell.execute_reply":"2025-04-06T06:49:01.122127Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-19-05ff9d98374a>:10: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n  train_df = kagglehub.load_dataset(\n","output_type":"stream"},{"name":"stdout","text":"First 5 records:    Score                                               Text  \\\n0      5  I received this product early from the seller!...   \n1      5  *****<br />Numi's Collection Assortment Melang...   \n2      5  I was very careful not to overcook this pasta,...   \n3      5  Buying this multi-pack I was misled by the pic...   \n4      5  These bars are so good! I loved them warmed up...   \n\n                                      Text_Processed  \n0  receive product early seller tastey great midd...  \n1  br numis collection assortment melange include...  \n2  careful overcook pasta make sure take bite eve...  \n3  buying multipack mislead picture whole hazel n...  \n4  bar good love warm definitely think great snac...  \n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Sample 10% of the data while keeping score distribution intact\nsampled_df, _ = train_test_split(\n    train_df, \n    test_size=0.9, \n    stratify=train_df['Score'], \n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:02.953748Z","iopub.execute_input":"2025-04-06T06:49:02.954020Z","iopub.status.idle":"2025-04-06T06:49:03.090423Z","shell.execute_reply.started":"2025-04-06T06:49:02.953997Z","shell.execute_reply":"2025-04-06T06:49:03.089772Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Extract the processed text and scores from the sampled data\n# Get text and adjusted scores (0–4 instead of 1–5)\ntrain_processed = sampled_df[\"Text_Processed\"].tolist()\ntrain_score = [s - 1 for s in sampled_df[\"Score\"].tolist()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:23.846316Z","iopub.execute_input":"2025-04-06T06:49:23.846610Z","iopub.status.idle":"2025-04-06T06:49:23.858851Z","shell.execute_reply.started":"2025-04-06T06:49:23.846588Z","shell.execute_reply":"2025-04-06T06:49:23.857933Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport tensorflow.compat.v1 as tf \nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tokenizers import BertWordPieceTokenizer\n\nimport transformers\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nimport logging\ntransformers.logging.set_verbosity_error()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:09:16.661351Z","iopub.execute_input":"2025-04-06T06:09:16.661743Z","iopub.status.idle":"2025-04-06T06:09:36.516841Z","shell.execute_reply.started":"2025-04-06T06:09:16.661708Z","shell.execute_reply":"2025-04-06T06:09:36.515936Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"training_sentences, test_sentences, training_labels, test_labels = train_test_split(train_processed, train_score, test_size=.4)\n\nvalidation_sentences, holdout_sentences, validation_labels, holdout_labels = train_test_split(test_sentences, test_labels, test_size=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:27.387396Z","iopub.execute_input":"2025-04-06T06:49:27.387683Z","iopub.status.idle":"2025-04-06T06:49:27.449001Z","shell.execute_reply.started":"2025-04-06T06:49:27.387656Z","shell.execute_reply":"2025-04-06T06:49:27.448029Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:28.741012Z","iopub.execute_input":"2025-04-06T06:49:28.741355Z","iopub.status.idle":"2025-04-06T06:49:28.960666Z","shell.execute_reply.started":"2025-04-06T06:49:28.741326Z","shell.execute_reply":"2025-04-06T06:49:28.959730Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"tokenizer([training_sentences[0]], truncation=True,\n                            padding=True, max_length=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:31.247125Z","iopub.execute_input":"2025-04-06T06:49:31.247506Z","iopub.status.idle":"2025-04-06T06:49:31.253641Z","shell.execute_reply.started":"2025-04-06T06:49:31.247481Z","shell.execute_reply":"2025-04-06T06:49:31.252740Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 8251, 1474, 5427, 16852, 8050, 2589, 1376, 3077, 1267, 3821, 1268, 7998, 7859, 1129, 13417, 3205, 190, 4661, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_encodings = tokenizer(training_sentences,\n                            truncation=True,\n                            padding=True)\n\nvalidation_encodings = tokenizer(validation_sentences,\n                            truncation=True,\n                            padding=True)\n\nholdout_encodings = tokenizer(holdout_sentences,\n                            truncation=True,\n                            padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:33.909319Z","iopub.execute_input":"2025-04-06T06:49:33.909609Z","iopub.status.idle":"2025-04-06T06:49:59.912176Z","shell.execute_reply.started":"2025-04-06T06:49:33.909586Z","shell.execute_reply":"2025-04-06T06:49:59.911194Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(train_encodings),\n                            training_labels\n                            ));\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(validation_encodings),\n                            validation_labels\n                            ));\n\nholdout_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(holdout_encodings),\n                            holdout_labels\n                            ));","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:49:59.913553Z","iopub.execute_input":"2025-04-06T06:49:59.913822Z","iopub.status.idle":"2025-04-06T06:51:08.051076Z","shell.execute_reply.started":"2025-04-06T06:49:59.913787Z","shell.execute_reply":"2025-04-06T06:51:08.050402Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model = TFBertForSequenceClassification.from_pretrained('bert-base-cased',num_labels=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:51:08.052707Z","iopub.execute_input":"2025-04-06T06:51:08.052922Z","iopub.status.idle":"2025-04-06T06:51:09.132085Z","shell.execute_reply.started":"2025-04-06T06:51:08.052903Z","shell.execute_reply":"2025-04-06T06:51:09.131166Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:51:09.133035Z","iopub.execute_input":"2025-04-06T06:51:09.133292Z","iopub.status.idle":"2025-04-06T06:51:09.145855Z","shell.execute_reply.started":"2025-04-06T06:51:09.133271Z","shell.execute_reply":"2025-04-06T06:51:09.144994Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n\n# Create and compile the model within the strategy scope\nwith strategy.scope():\n    model = TFBertForSequenceClassification.from_pretrained('bert-base-cased',num_labels=5)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")])\n    \nhistory = model.fit(train_dataset.shuffle(100).batch(8),\n          epochs=3,\n          batch_size=64,\n          validation_data=validation_dataset.shuffle(100).batch(8), verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:51:09.146682Z","iopub.execute_input":"2025-04-06T06:51:09.146969Z","iopub.status.idle":"2025-04-06T08:11:05.647248Z","shell.execute_reply.started":"2025-04-06T06:51:09.146925Z","shell.execute_reply":"2025-04-06T08:11:05.646307Z"}},"outputs":[{"name":"stdout","text":"Number of devices: 2\nEpoch 1/3\n2319/2319 [==============================] - 1629s 686ms/step - loss: 0.9023 - accuracy: 0.6732 - val_loss: 0.8136 - val_accuracy: 0.6929\nEpoch 2/3\n2319/2319 [==============================] - 1582s 682ms/step - loss: 0.7225 - accuracy: 0.7315 - val_loss: 0.8143 - val_accuracy: 0.6967\nEpoch 3/3\n2319/2319 [==============================] - 1583s 683ms/step - loss: 0.5505 - accuracy: 0.7954 - val_loss: 0.9200 - val_accuracy: 0.6723\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Install dependencies as needed:\n# pip install kagglehub[pandas-datasets]\nimport kagglehub\nfrom kagglehub import KaggleDatasetAdapter\n\n# Set the path to the file you'd like to load\nfile_path = \"test_processed.csv\"\n\n# Load the latest version\ntest_df = kagglehub.load_dataset(\n  KaggleDatasetAdapter.PANDAS,\n  \"buddycyph/test-processed\",\n  file_path,\n  # Provide any additional arguments like \n  # sql_query or pandas_kwargs. See the \n  # documenation for more information:\n  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n)\n\nprint(\"First 5 records:\", test_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T08:15:25.577688Z","iopub.execute_input":"2025-04-06T08:15:25.577974Z","iopub.status.idle":"2025-04-06T08:15:26.495987Z","shell.execute_reply.started":"2025-04-06T08:15:25.577952Z","shell.execute_reply":"2025-04-06T08:15:26.495273Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-31-5f8e7ae509f2>:10: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n  test_df = kagglehub.load_dataset(\n","output_type":"stream"},{"name":"stdout","text":"First 5 records:    Id                                               Text  \\\n0   0  Fog chaser was the best both in flavor and bod...   \n1   1  We found this at PF Changs, and it tastes just...   \n2   2  Not quite a chocolate bar substitute but delic...   \n3   3  This is not as tasty as Pamela's Almond Biscot...   \n4   4  <a href=\"http://www.amazon.com/gp/product/B000...   \n\n                                      Text_Processed  \n0  fog chaser best flavor body far product body c...  \n1        found pf chang taste great bag per box list  \n2  quite chocolate bar substitute delicious anywa...  \n3  tasty pamelas almond biscotti good chocolate b...  \n4  hrefhttpwwwamazoncomgpproductbzgold mother hub...  \n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"file_path = \"sampleSubmission.csv\"\n\n# Load the latest version\nsample_submission = kagglehub.load_dataset(\n  KaggleDatasetAdapter.PANDAS,\n  \"buddycyph/samplesubmission\",\n  file_path,\n  # Provide any additional arguments like \n  # sql_query or pandas_kwargs. See the \n  # documenation for more information:\n  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T08:16:02.326619Z","iopub.execute_input":"2025-04-06T08:16:02.326897Z","iopub.status.idle":"2025-04-06T08:16:07.511919Z","shell.execute_reply.started":"2025-04-06T08:16:02.326876Z","shell.execute_reply":"2025-04-06T08:16:07.510984Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-32-a7175d73b4df>:4: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n  sample_submission = kagglehub.load_dataset(\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"test_texts = test_df['Text_Processed'].dropna().tolist()  # Drop NaN values and convert to list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T08:28:06.704175Z","iopub.execute_input":"2025-04-06T08:28:06.704475Z","iopub.status.idle":"2025-04-06T08:28:06.725943Z","shell.execute_reply.started":"2025-04-06T08:28:06.704453Z","shell.execute_reply":"2025-04-06T08:28:06.725223Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Assuming you have 'test_sentences' (the sentences in your test set) and 'test_labels' (the labels for evaluation)\ntest_encodings = tokenizer(test_texts,\n                           truncation=True,\n                           padding=True)  # Adjust max_length if necessary\n\n# Create a TensorFlow dataset from the encoded test data\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),\n))\n\n# Batch the test dataset (adjust batch size as needed)\ntest_dataset = test_dataset.batch(8)  # Adjust batch size to match your training batch size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T08:28:16.765501Z","iopub.execute_input":"2025-04-06T08:28:16.765959Z","iopub.status.idle":"2025-04-06T08:34:22.601628Z","shell.execute_reply.started":"2025-04-06T08:28:16.765921Z","shell.execute_reply":"2025-04-06T08:34:22.600918Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"predictions = model.predict(test_dataset, verbose=1)\npredicted_classes = tf.argmax(predictions.logits, axis=-1)\npredicted_classes = predicted_classes + 1 \nprint(predicted_classes.numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T08:34:51.899821Z","iopub.execute_input":"2025-04-06T08:34:51.900182Z","iopub.status.idle":"2025-04-06T09:22:27.074059Z","shell.execute_reply.started":"2025-04-06T08:34:51.900127Z","shell.execute_reply":"2025-04-06T09:22:27.073261Z"}},"outputs":[{"name":"stdout","text":"14958/14958 [==============================] - 2846s 190ms/step\n[5 5 5 ... 4 5 5]\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\npredicted_classes_with_placeholder = np.append(predicted_classes.numpy(), [5])\n\n# Step 2: Update the 'Score' column in the sample_submission DataFrame\nsample_submission['Score'] = predicted_classes_with_placeholder\n\n# Step 3: Ensure the missing row (98060) gets the placeholder (5)\nsample_submission.loc[98060, 'Score'] = 5  # Setting placeholder as 5\n\n# Step 4: Save the DataFrame to a CSV file\nsample_submission.to_csv(\"thickofit.csv\", index=False)\n\nprint(sample_submission.head()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:38:47.117062Z","iopub.execute_input":"2025-04-06T09:38:47.117370Z","iopub.status.idle":"2025-04-06T09:38:47.196291Z","shell.execute_reply.started":"2025-04-06T09:38:47.117346Z","shell.execute_reply":"2025-04-06T09:38:47.195595Z"}},"outputs":[{"name":"stdout","text":"   Id  Score\n0   0      5\n1   1      5\n2   2      5\n3   3      5\n4   4      5\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}