{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YfQ8TyPJFsR2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train_processed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "24A7qMfvGKdW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to pass into N-gram and Vector Space\n",
        "X = train_df['Text_Processed'].tolist()\n",
        "y = [score - 1 for score in train_df['Score'].tolist()]\n",
        "\n",
        "# Splitting the dataset to 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_subset, _, y_train_subset, _ = train_test_split(X_train, y_train, train_size=0.1, random_state=42)\n",
        "\n",
        "# You can also limit the subset of the test data if needed\n",
        "X_test_subset, _, y_test_subset, _ = train_test_split(X_test, y_test, train_size=0.1, random_state=42)\n",
        "\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
        "    \"Naïve Bayes\": MultinomialNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        'classifier__C': [0.1, 1, 10],\n",
        "        'classifier__solver': ['liblinear']\n",
        "    },\n",
        "    \"Decision Tree\": {\n",
        "        'classifier__max_depth': [5, 10, 20],  # Depth of the tree\n",
        "        'classifier__min_samples_split': [2, 5, 10],  # Minimum samples to split an internal node\n",
        "        'classifier__min_samples_leaf': [1, 2, 4],  # Minimum samples required at each leaf node\n",
        "        'classifier__criterion': ['gini', 'entropy']  # The function to measure quality of a split\n",
        "    },\n",
        "    \"Naïve Bayes\": {\n",
        "        'classifier__alpha': [0.1, 1.0, 10.0],  # for Laplace smoothing\n",
        "        'classifier__fit_prior': [True, False]  # whether to learn class prior probabilities\n",
        "    },\n",
        "}\n",
        "\n",
        "results = []"
      ],
      "metadata": {
        "id": "RD4k12_pGLc2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_space_models = {\n",
        "    \"Binary Representation\": CountVectorizer(binary=True),\n",
        "    \"Frequency Count\": CountVectorizer(max_features=10000, max_df=.15),\n",
        "    \"TF-IDF\": TfidfVectorizer(max_features=10000, max_df=.15)\n",
        "}"
      ],
      "metadata": {
        "id": "gcOkgEAsGRxp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"\\n=== {clf_name} ===\")\n",
        "\n",
        "    for ngram_name, vectorizer in vector_space_models.items():\n",
        "        print(f\"-- {ngram_name} --\")\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', clf)\n",
        "        ])\n",
        "\n",
        "        param_grid = param_grids[clf_name]\n",
        "\n",
        "        if param_grid:\n",
        "            # Perform RandomizedSearchCV\n",
        "            search = RandomizedSearchCV(\n",
        "                pipeline,\n",
        "                param_distributions=param_grid,\n",
        "                n_iter=5,\n",
        "                cv=3,\n",
        "                scoring='accuracy',\n",
        "                n_jobs=-1,\n",
        "                verbose=0\n",
        "            )\n",
        "            search.fit(X_train_subset, y_train_subset)\n",
        "            best_model = search.best_estimator_\n",
        "\n",
        "            # Print best hyperparameters\n",
        "            print(f\"Best Hyperparameters: {search.best_params_}\")\n",
        "        else:\n",
        "            pipeline.fit(X_train_subset, y_train_subset)\n",
        "            best_model = pipeline\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = best_model.predict(X_test_subset)\n",
        "\n",
        "        accuracy = accuracy_score(y_test_subset, y_pred)\n",
        "        precision = precision_score(y_test_subset, y_pred, average='weighted', zero_division=1)\n",
        "        recall = recall_score(y_test_subset, y_pred, average='weighted', zero_division=1)\n",
        "        f1 = f1_score(y_test_subset, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "        # Print evaluation results\n",
        "        print(classification_report(y_test_subset, y_pred, zero_division=1))\n",
        "\n",
        "        # Store results\n",
        "        results.append([\"Vector Space\", clf_name, ngram_name, accuracy, precision, recall, f1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thrp5LUFGUwl",
        "outputId": "878c14a6-0238-49e9-b832-e1d635bbcbbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "-- Binary Representation --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'classifier__solver': 'liblinear', 'classifier__C': 0.1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.49      0.53       534\n",
            "           1       0.33      0.08      0.13       323\n",
            "           2       0.39      0.14      0.20       463\n",
            "           3       0.38      0.17      0.24       870\n",
            "           4       0.75      0.96      0.84      3992\n",
            "\n",
            "    accuracy                           0.70      6182\n",
            "   macro avg       0.49      0.37      0.39      6182\n",
            "weighted avg       0.63      0.70      0.64      6182\n",
            "\n",
            "-- Frequency Count --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'classifier__solver': 'liblinear', 'classifier__C': 0.1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.43      0.49       534\n",
            "           1       0.21      0.04      0.07       323\n",
            "           2       0.35      0.12      0.18       463\n",
            "           3       0.37      0.16      0.22       870\n",
            "           4       0.74      0.95      0.83      3992\n",
            "\n",
            "    accuracy                           0.69      6182\n",
            "   macro avg       0.45      0.34      0.36      6182\n",
            "weighted avg       0.61      0.69      0.63      6182\n",
            "\n",
            "-- TF-IDF --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'classifier__solver': 'liblinear', 'classifier__C': 1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.38      0.46       534\n",
            "           1       0.42      0.03      0.06       323\n",
            "           2       0.37      0.06      0.11       463\n",
            "           3       0.35      0.13      0.19       870\n",
            "           4       0.72      0.97      0.83      3992\n",
            "\n",
            "    accuracy                           0.69      6182\n",
            "   macro avg       0.49      0.32      0.33      6182\n",
            "weighted avg       0.61      0.69      0.61      6182\n",
            "\n",
            "\n",
            "=== Naïve Bayes ===\n",
            "-- Binary Representation --\n",
            "Best Hyperparameters: {'classifier__fit_prior': False, 'classifier__alpha': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.36      0.45       534\n",
            "           1       0.22      0.01      0.01       323\n",
            "           2       0.22      0.02      0.04       463\n",
            "           3       0.28      0.15      0.20       870\n",
            "           4       0.71      0.96      0.82      3992\n",
            "\n",
            "    accuracy                           0.67      6182\n",
            "   macro avg       0.41      0.30      0.30      6182\n",
            "weighted avg       0.58      0.67      0.60      6182\n",
            "\n",
            "-- Frequency Count --\n",
            "Best Hyperparameters: {'classifier__fit_prior': True, 'classifier__alpha': 0.1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.54      0.50       534\n",
            "           1       0.23      0.15      0.18       323\n",
            "           2       0.26      0.20      0.23       463\n",
            "           3       0.31      0.27      0.29       870\n",
            "           4       0.80      0.85      0.83      3992\n",
            "\n",
            "    accuracy                           0.66      6182\n",
            "   macro avg       0.41      0.40      0.40      6182\n",
            "weighted avg       0.63      0.66      0.64      6182\n",
            "\n",
            "-- TF-IDF --\n",
            "Best Hyperparameters: {'classifier__fit_prior': True, 'classifier__alpha': 0.1}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.23      0.35       534\n",
            "           1       0.57      0.01      0.02       323\n",
            "           2       0.29      0.01      0.02       463\n",
            "           3       0.30      0.03      0.06       870\n",
            "           4       0.67      0.99      0.80      3992\n",
            "\n",
            "    accuracy                           0.67      6182\n",
            "   macro avg       0.50      0.26      0.25      6182\n",
            "weighted avg       0.59      0.67      0.56      6182\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "-- Binary Representation --\n",
            "Best Hyperparameters: {'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 5, 'classifier__criterion': 'gini'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.16      0.22       534\n",
            "           1       0.17      0.00      0.01       323\n",
            "           2       0.00      0.00      0.00       463\n",
            "           3       0.38      0.00      0.01       870\n",
            "           4       0.66      0.98      0.79      3992\n",
            "\n",
            "    accuracy                           0.65      6182\n",
            "   macro avg       0.31      0.23      0.21      6182\n",
            "weighted avg       0.52      0.65      0.53      6182\n",
            "\n",
            "-- Frequency Count --\n",
            "Best Hyperparameters: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': 10, 'classifier__criterion': 'entropy'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.17      0.23       534\n",
            "           1       0.10      0.01      0.01       323\n",
            "           2       0.27      0.05      0.09       463\n",
            "           3       0.37      0.04      0.07       870\n",
            "           4       0.67      0.97      0.79      3992\n",
            "\n",
            "    accuracy                           0.65      6182\n",
            "   macro avg       0.36      0.25      0.24      6182\n",
            "weighted avg       0.54      0.65      0.55      6182\n",
            "\n",
            "-- TF-IDF --\n",
            "Best Hyperparameters: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 10, 'classifier__criterion': 'entropy'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.15      0.21       534\n",
            "           1       0.14      0.01      0.02       323\n",
            "           2       0.26      0.06      0.10       463\n",
            "           3       0.37      0.07      0.12       870\n",
            "           4       0.67      0.96      0.79      3992\n",
            "\n",
            "    accuracy                           0.65      6182\n",
            "   macro avg       0.37      0.25      0.25      6182\n",
            "weighted avg       0.55      0.65      0.56      6182\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(solver='liblinear', C=0.1, max_iter=500)\n",
        "\n",
        "# Create a pipeline with the classifier\n",
        "pipeline_full = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(binary=True)),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', C=0.1, max_iter=500))\n",
        "])\n",
        "\n",
        "# Train the model on the full training dataset\n",
        "pipeline_full.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_full = pipeline_full.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f\"Accuracy on Test Set: {accuracy_full:.4f}\")\n",
        "\n",
        "# Print the classification report for more detailed evaluation\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_full, zero_division=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag6NSw5CGjEy",
        "outputId": "116cf874-e2ef-49a3-f23e-c5437b37d0a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 0.7154\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.59      0.62      5644\n",
            "           1       0.38      0.09      0.14      3214\n",
            "           2       0.42      0.19      0.26      4679\n",
            "           3       0.44      0.19      0.27      8688\n",
            "           4       0.76      0.96      0.85     39602\n",
            "\n",
            "    accuracy                           0.72     61827\n",
            "   macro avg       0.53      0.40      0.43     61827\n",
            "weighted avg       0.66      0.72      0.67     61827\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OW_9rH6XTmYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}